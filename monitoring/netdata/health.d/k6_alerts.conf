# ============================================================================
# K6 STRESS TESTING ALERTS - NETDATA
# Ensurance Pharmacy Monitoring System
# ============================================================================
# Estas alertas monitorean pruebas de carga K6
# Basado en los umbrales del dashboard de Grafana k6-dashboard.json
# Las alertas se envían a Prometheus Alertmanager que luego las envía por Email y Slack
# ============================================================================

# Alerta: Alta tasa de errores en K6
# Lógica: Si la tasa de errores excede 5% (crítico) o 1% (warning) por 1 minuto
# Se envía correo y notificación de Slack cuando la tasa de errores sobrepase el 1%
alarm: netdata_k6_high_error_rate
   on: k6_http_req_failed
 calc: $this * 100
units: %
every: 10s
 warn: $this > 1
 crit: $this > 5
delay: up 1m down 3m
 info: K6 stress test tiene alta tasa de errores. \
       WARNING > 1%, CRITICAL > 5%. \
       Se envía correo y notificación de Slack cuando la tasa de errores sobrepase el 1%.
   to: webmaster

# Alerta: Response Time p95 alto en K6
# Lógica: Si el percentil 95 de tiempo de respuesta excede 1000ms (crítico) o 500ms (warning)
# Se envía correo y notificación de Slack cuando el p95 sobrepase 500ms
alarm: netdata_k6_high_response_time_p95
   on: k6_http_req_duration
 calc: $p95
units: ms
every: 10s
 warn: $this > 500
 crit: $this > 1000
delay: up 2m down 5m
 info: K6 stress test p95 response time es alto. \
       WARNING > 500ms, CRITICAL > 1000ms. \
       Se envía correo y notificación de Slack cuando el p95 sobrepase 500ms.
   to: webmaster

# Alerta: Response Time p99 muy alto en K6
alarm: netdata_k6_high_response_time_p99
   on: k6_http_req_duration
 calc: $p99
units: ms
every: 10s
 warn: $this > 2000
 crit: $this > 5000
delay: up 1m down 3m
 info: K6 stress test p99 response time muy alto. \
       WARNING > 2s, CRITICAL > 5s.
   to: webmaster

# Alerta: Checks fallando en K6
# Lógica: Si hay checks que están fallando durante el test de carga
alarm: netdata_k6_failed_checks
   on: k6_checks
 calc: $fail
units: checks
every: 10s
 warn: $this > 0
 crit: $this > 5
delay: up 1m down 3m
 info: K6 stress test tiene checks fallando. \
       WARNING > 0, CRITICAL > 5. \
       Se envía correo y notificación de Slack cuando haya checks fallando.
   to: webmaster

# Alerta: Alta tasa de requests en K6 (informativo)
alarm: netdata_k6_high_request_rate
   on: k6_http_reqs
 calc: $this
units: requests/s
every: 10s
 warn: $this > 1000
delay: up 2m down 5m
 info: K6 stress test ejecutándose con alta carga. \
       Informativo: > 1000 req/s.
   to: webmaster

# Alerta: Muchos usuarios virtuales activos (informativo)
alarm: netdata_k6_high_virtual_users
   on: k6_vus
 calc: $active
units: VUs
every: 10s
 warn: $this > 100
delay: up 1m down 3m
 info: K6 stress test con muchos usuarios virtuales activos. \
       Informativo: > 100 VUs.
   to: webmaster

# Alerta: K6 test con duración excesiva
alarm: netdata_k6_long_running_test
   on: k6_iteration_duration
 calc: $avg
units: ms
every: 30s
 warn: $this > 30000
 crit: $this > 60000
delay: up 5m down 10m
 info: Iteración de K6 tomando mucho tiempo. \
       WARNING > 30s, CRITICAL > 60s.
   to: webmaster
