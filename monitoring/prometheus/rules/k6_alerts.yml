# ALERTAS DE K6 STRESS TESTING
# Monitorea performance durante tests de carga

groups:
  - name: k6_performance_alerts
    interval: 15s
    rules:
      # ALERTA 33: Alta tasa de errores en K6
      - alert: K6HighErrorRate
        expr: k6_http_req_failed > 0.05
        for: 1m
        labels:
          severity: critical
          service: k6-stress-testing
          component: load-test
        annotations:
          summary: "üî¥ K6 Test: Alta tasa de errores - Aplicaci√≥n fallando bajo carga"
          description: "El test de carga K6 est√° detectando {{ $value | humanizePercentage }} de errores (umbral cr√≠tico: 5%). M√°s del 5% de requests est√°n fallando. Esto indica que la aplicaci√≥n NO soporta la carga actual - puede estar: crasheando, con timeouts, retornando 500s, o DB saturada. El sistema FALLAR√çA en producci√≥n con esta carga."
          dashboard: "http://localhost:3302/d/k6-stress-test"
          action: "üö® NO DESPLEGAR: 1) Ver logs de aplicaci√≥n durante test. 2) Reducir carga de K6 para encontrar l√≠mite. 3) Identificar endpoint que falla. 4) Optimizar c√≥digo/queries. 5) Escalar recursos antes de produccion. 6) Repetir test hasta lograr <1% errores."
      
      # ALERTA 34: Response time p95 alto
      - alert: K6HighResponseTimeP95
        expr: k6_http_req_duration{quantile="0.95"} > 1000
        for: 2m
        labels:
          severity: warning
          service: k6-stress-testing
          component: performance
        annotations:
          summary: "‚ö†Ô∏è K6 Test: Response time P95 alto - Performance degradado"
          description: "El percentil 95 de tiempo de respuesta es {{ $value | humanize }}ms (umbral: 1000ms). Esto significa que el 5% de usuarios m√°s lentos esperan m√°s de 1 segundo. Bajo carga, la aplicaci√≥n est√° lenta. En producci√≥n, usuarios experimentar√≠an lentitud notable. Necesita optimizaci√≥n antes de desplegar."
          dashboard: "http://localhost:3302/d/k6-stress-test"
          action: "üîç Optimizar: 1) Ver endpoints lentos en K6 output. 2) Revisar queries de DB sin √≠ndices. 3) Implementar cach√©. 4) Optimizar c√≥digo ineficiente. 5) Agregar CDN para assets. 6) Considerar scaling horizontal. Target: P95 < 500ms."
      
      # ALERTA 35: Response time p95 cr√≠tico
      - alert: K6CriticalResponseTimeP95
        expr: k6_http_req_duration{quantile="0.95"} > 3000
        for: 1m
        labels:
          severity: critical
          service: k6-stress-testing
          component: performance
        annotations:
          summary: "üî¥ K6 Test: Response time P95 CR√çTICO - Sistema INACEPTABLE"
          description: "¬°CR√çTICO! El P95 es {{ $value | humanize }}ms (umbral cr√≠tico: 3000ms = 3 segundos). El 5% de usuarios espera M√ÅS DE 3 SEGUNDOS por respuesta. Esto es completamente inaceptable para producci√≥n. Los usuarios abandonar√≠an el sitio. El sistema est√° severamente degradado bajo carga. NO APTO PARA PRODUCCION."
          dashboard: "http://localhost:3302/d/k6-stress-test"
          action: "üö® NO DESPLEGAR: 1) DETENER test. 2) Reducir carga para encontrar punto de quiebre. 3) Perfilar aplicaci√≥n. 4) Identificar cuello de botella cr√≠tico. 5) Refactorizar urgente. 6) Escalar verticalmente/horizontalmente. 7) Re-arquitecturar si es necesario."
      
      # ALERTA 36: Response time p99 muy alto
      - alert: K6HighResponseTimeP99
        expr: k6_http_req_duration{quantile="0.99"} > 5000
        for: 1m
        labels:
          severity: warning
          service: k6-stress-testing
          component: performance
        annotations:
          summary: "‚ö†Ô∏è K6 Test: Response time P99 extremo - Outliers preocupantes"
          description: "El percentil 99 es {{ $value | humanize }}ms (umbral: 5000ms). El 1% de usuarios m√°s desafortunados espera M√ÅS DE 5 SEGUNDOS. Aunque es un porcentaje peque√±o, representa experiencia p√©sima para algunos usuarios. Indica variabilidad alta - algunos requests son extremadamente lentos (outliers)."
          dashboard: "http://localhost:3302/d/k6-stress-test"
          action: "üîç Investigar outliers: 1) Ver requests individuales lentos en K6. 2) Buscar: queries N+1, operaciones s√≠ncronas pesadas, timeouts. 3) Implementar timeouts agresivos. 4) Cacha operaciones costosas. 5) Usar async/queues para operaciones pesadas. Target: P99 < 2000ms."
      
      # ALERTA 37: Checks fallando en K6
      - alert: K6FailedChecks
        expr: k6_checks{result="fail"} > 0
        for: 1m
        labels:
          severity: warning
          service: k6-stress-testing
          component: validation
        annotations:
          summary: "‚ö†Ô∏è K6 Test: Checks fallando - Validaciones incorrectas"
          description: "{{ $value }} validaciones (checks) de K6 han fallado. Los checks validan que las respuestas sean correctas (status 200, contenido esperado, headers, etc.). Si fallan, significa que la aplicaci√≥n est√° retornando respuestas incorrectas o incompletas bajo carga. Funcionalidad degradada."
          dashboard: "http://localhost:3302/d/k6-stress-test"
          action: "üîç Depurar checks: 1) Ver cu√°l check falla: revisar K6 output. 2) Ver respuesta real vs esperada. 3) Reproducir request manualmente. 4) Revisar c√≥digo del endpoint. 5) Verificar que DB tenga datos correctos. 6) Ajustar check si expectativa es incorrecta."
      
      # ALERTA 38: Alta tasa de requests
      - alert: K6HighRequestRate
        expr: rate(k6_http_reqs[1m]) > 1000
        for: 2m
        labels:
          severity: info
          service: k6-stress-testing
          component: load
        annotations:
          summary: "‚ÑπÔ∏è K6 Test: Alta carga activa - {{ $value | humanize }} req/s"
          description: "INFO: Test de estr√©s K6 est√° generando {{ $value | humanize }} requests por segundo (threshold informativo: >1000). Esta es una alerta informativa para notificar que hay un test de carga intenso corriendo. Esto es NORMAL y ESPERADO durante pruebas de estr√©s. √öNICAMENTE preocupante si no hay test programado."
          dashboard: "http://localhost:3302/d/k6-stress-test"
          action: "‚úÖ Normal durante testing. 1) Verificar si test est√° programado. 2) Monitorear m√©tricas de la aplicaci√≥n. 3) Si NO hay test programado, investigar qui√©n ejecut√≥ K6. 4) Revisar que aplicaci√≥n soporte la carga. 5) Documentar resultados del test."
      
      # ALERTA 39: Muchos VUs activos
      - alert: K6HighVirtualUsers
        expr: k6_vus > 100
        for: 1m
        labels:
          severity: info
          service: k6-stress-testing
          component: load
        annotations:
          summary: "‚ÑπÔ∏è K6 Test: {{ $value }} usuarios virtuales activos - Test en progreso"
          description: "INFO: K6 est√° simulando {{ $value }} usuarios virtuales concurrentes (threshold informativo: >100). Esta es una notificaci√≥n de que hay un test de carga con muchos VUs ejecut√°ndose. Es NORMAL durante stress testing. Cada VU simula un usuario real haciendo requests. M√°s VUs = m√°s carga."
          dashboard: "http://localhost:3302/d/k6-stress-test"
          action: "‚úÖ Normal durante testing. 1) Verificar test programado. 2) Monitorear CPU/RAM de aplicaci√≥n bajo esta carga. 3) Documentar comportamiento. 4) Verificar que sea un test leg√≠timo. 5) Usar resultados para capacity planning."

  - name: k6_availability_alerts
    interval: 30s
    rules:
      # ALERTA 40: K6 Pushgateway no recibe m√©tricas
      - alert: K6MetricsNotReceived
        expr: time() - push_time_seconds{job="k6-stress-test"} > 300
        for: 1m
        labels:
          severity: warning
          service: k6-stress-testing
          component: metrics
        annotations:
          summary: "‚ö†Ô∏è K6 Pushgateway: No recibe m√©tricas - Test detenido o fallando"
          description: "El Pushgateway no ha recibido m√©tricas de K6 en los √∫ltimos 5 minutos. Esto significa que: test de K6 termin√≥, K6 crash√≥, Pushgateway ca√≠do, o problema de red. Sin m√©tricas no podemos monitorear los tests de carga. Si el test deber√≠a estar corriendo, hay un problema."
          dashboard: "http://localhost:9093"
          action: "üîç Verificar K6: 1) Ver si K6 est√° corriendo: 'docker ps | grep k6'. 2) Ver logs: 'docker logs [k6-container]'. 3) Verificar Pushgateway: 'curl http://localhost:9091/metrics'. 4) Re-ejecutar test K6 si fall√≥. 5) Revisar conectividad entre K6 y Pushgateway."
